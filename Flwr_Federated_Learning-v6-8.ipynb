{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Allenyang2/PytorchFL/blob/main/Flwr_Federated_Learning-v6-8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "numpy.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "zutFbeeXI2rp",
        "outputId": "d2fb7b7d-879e-45f6-8e06-6c9439ae782b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.22.4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcyG6G1-kc7E",
        "outputId": "3a48ce06-b7b5-4977-b83d-4ba7beec70db"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "U82RNhuvFD4N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0985730b-5b62-4cda-be12-a56370a12fa6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.2/157.2 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.6/58.6 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m82.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m72.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.4/201.4 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m83.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.5/468.5 kB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for gpustat (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q flwr[simulation] torch torchvision matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1siY2CwFD4O",
        "outputId": "3cc4d2fe-bc80-486d-ec17-9a6c76bf9805"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on cuda using PyTorch 2.0.1+cu118 and Flower 1.4.0\n"
          ]
        }
      ],
      "source": [
        "from collections import OrderedDict\n",
        "from typing import List, Tuple\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision.datasets import CIFAR10\n",
        "import sys\n",
        "import random\n",
        "import flwr as fl\n",
        "from flwr.common import Metrics\n",
        "\n",
        "DEVICE = torch.device(\"cuda\")  # Try \"cuda\" to train on GPU\n",
        "print(\n",
        "    f\"Training on {DEVICE} using PyTorch {torch.__version__} and Flower {fl.__version__}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4eigscBeFD4P"
      },
      "source": [
        "It is possible to switch to a runtime that has GPU acceleration enabled (on \n",
        "\n",
        "*   List item\n",
        "*   List item\n",
        "\n",
        "Google Colab: `Runtime > Change runtime type > Hardware acclerator: GPU > Save`). Note, however, that Google Colab is not always able to offer GPU acceleration. If you see an error related to GPU availability in one of the following sections, consider switching back to CPU-based execution by setting `DEVICE = torch.device(\"cpu\")`. If the runtime has GPU acceleration enabled, you should see the output `Training on cuda`, otherwise it'll say `Training on cpu`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "v8xH4jXVFD4P"
      },
      "outputs": [],
      "source": [
        "CLASSES = (\n",
        "    \"plane\",\n",
        "    \"car\",\n",
        "    \"bird\",\n",
        "    \"cat\",\n",
        "    \"deer\",\n",
        "    \"dog\",\n",
        "    \"frog\",\n",
        "    \"horse\",\n",
        "    \"ship\",\n",
        "    \"truck\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYnW44A4FD4P"
      },
      "source": [
        "We simulate having multiple datasets from multiple organizations (also called the \"cross-silo\" setting in federated learning) by splitting the original CIFAR-10 dataset into multiple partitions. Each partition will represent the data from a single organization. We're doing this purely for experimentation purposes, in the real world there's no need for data splitting because each organization already has their own data (so the data is naturally partitioned).\n",
        "\n",
        "Each organization will act as a client in the federated learning system. So having ten organizations participate in a federation means having ten clients connected to the federated learning server:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Mvz_K3tSFD4Q"
      },
      "outputs": [],
      "source": [
        "NUM_CLIENTS = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PnC4F6PFD4Q"
      },
      "source": [
        "\n",
        "Let's now load the CIFAR-10 training and test set, partition them into ten smaller datasets (each split into training and validation set), and wrap the resulting partitions by creating a PyTorch `DataLoader` for each of them:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "1sKAXxa7FD4Q"
      },
      "outputs": [],
      "source": [
        "# BATCH_SIZE = 32\n",
        "\n",
        "\n",
        "# def load_datasets():\n",
        "#     # Download and transform CIFAR-10 (train and test)\n",
        "#     transform = transforms.Compose(\n",
        "#         [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
        "#     )\n",
        "#     trainset = CIFAR10(\"./dataset\", train=True, download=True, transform=transform)\n",
        "#     testset = CIFAR10(\"./dataset\", train=False, download=True, transform=transform)\n",
        "\n",
        "#     # Split training set into 10 partitions to simulate the individual dataset\n",
        "#     partition_size = len(trainset) // NUM_CLIENTS\n",
        "#     lengths = [partition_size] * NUM_CLIENTS\n",
        "#     datasets = random_split(trainset, lengths, torch.Generator().manual_seed(42))\n",
        "\n",
        "#     # Split each partition into train/val and create DataLoader\n",
        "#     trainloaders = []\n",
        "#     valloaders = []\n",
        "#     for ds in datasets:\n",
        "#         len_val = len(ds) // 10  # 10 % validation set\n",
        "#         len_train = len(ds) - len_val\n",
        "#         lengths = [len_train, len_val]\n",
        "#         ds_train, ds_val = random_split(ds, lengths, torch.Generator().manual_seed(42))\n",
        "#         trainloaders.append(DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True))\n",
        "#         valloaders.append(DataLoader(ds_val, batch_size=BATCH_SIZE))\n",
        "#     testloader = DataLoader(testset, batch_size=BATCH_SIZE)\n",
        "#     return trainloaders, valloaders, testloader\n",
        "\n",
        "\n",
        "# trainloaders, valloaders, testloader = load_datasets()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "import random\n",
        "\n",
        "def load_datasets(strategy: str = 'equal') -> Tuple[List[DataLoader], List[DataLoader], DataLoader]:\n",
        "\n",
        "    # Download and transform CIFAR-10 (train and test)\n",
        "    transform = transforms.Compose(\n",
        "        [transforms.ToTensor(), \n",
        "         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
        "    )\n",
        "    trainset = CIFAR10(\"./dataset\", train=True, download=True, transform=transform)\n",
        "    testset = CIFAR10(\"./dataset\", train=False, download=True, transform=transform)\n",
        "\n",
        "    if strategy == 'equal':\n",
        "        # Split training set into 10 partitions to simulate the individual dataset\n",
        "        partition_size = len(trainset) // NUM_CLIENTS\n",
        "        lengths = [partition_size] * NUM_CLIENTS\n",
        "        datasets = random_split(trainset, lengths, torch.Generator().manual_seed(42))\n",
        "    elif strategy == 'non-iid':\n",
        "        # Select random classes for each client (non-iid)\n",
        "        labels = np.array(trainset.targets)\n",
        "        idx = np.arange(len(trainset))\n",
        "        class_indices = [idx[labels == i] for i in range(len(CLASSES))]\n",
        "        datasets = []\n",
        "        for i in range(NUM_CLIENTS):\n",
        "            # Randomly choose classes for this client\n",
        "            classes = np.random.choice(len(CLASSES), size=5, replace=False)\n",
        "            # Select a fixed number of samples from each class\n",
        "            samples = [class_indices[c][i * 100:(i + 1) * 100] for c in classes]\n",
        "            samples = np.concatenate(samples)\n",
        "            dataset = torch.utils.data.Subset(trainset, samples)\n",
        "            datasets.append(dataset)\n",
        "    elif strategy == 'random-percentage':\n",
        "        # Randomly divide training data into NUM_CLIENTS subsets with different class distributions\n",
        "        # Divide the training set randomly with different percentage distribution of classes\n",
        "        class_count = {i: 0 for i in range(len(CLASSES))}\n",
        "        for i in range(len(trainset)):\n",
        "            label = trainset[i][1]\n",
        "            class_count[label] += 1\n",
        "        partitions = [[] for _ in range(NUM_CLIENTS)]\n",
        "        for i in range(len(CLASSES)):\n",
        "            class_indices = [j for j in range(len(trainset)) if trainset[j][1] == i]\n",
        "            random.shuffle(class_indices)\n",
        "            partition_sizes = []\n",
        "            for k in range(NUM_CLIENTS):\n",
        "                if k == NUM_CLIENTS - 1:\n",
        "                    partition_sizes.append(len(class_indices) - sum(partition_sizes))\n",
        "                else:\n",
        "                    partition_sizes.append(random.randint(0, len(class_indices) - sum(partition_sizes)))\n",
        "            partition_start = 0\n",
        "            for k in range(NUM_CLIENTS):\n",
        "                partition = class_indices[partition_start:partition_start+partition_sizes[k]]\n",
        "                partitions[k].extend(partition)\n",
        "                partition_start += partition_sizes[k]\n",
        "        datasets = [torch.utils.data.Subset(trainset, partition) for partition in partitions]\n",
        "    elif strategy == 'random-size':\n",
        "        # Generate a list of random numbers that add up to the total number of samples minus NUM_CLIENTS\n",
        "        # This ensures that each client gets at least one sample\n",
        "        sizes = np.random.dirichlet(np.ones(NUM_CLIENTS), size=1) * (len(trainset) - NUM_CLIENTS)\n",
        "        #https://numpy.org/doc/stable/reference/random/generated/numpy.random.dirichlet.html\n",
        "        sizes = np.rint(sizes)  # Round to the nearest integers\n",
        "        sizes = list(map(int, sizes.flatten()))  # Convert to a list of integers\n",
        "        sizes = [size + 1 for size in sizes]  # Add one to each size to ensure each client gets at least one sample\n",
        "        sizes[-1] = len(trainset) - np.sum(sizes[:-1])  # Ensure the sizes add up to the total number of samples\n",
        "\n",
        "        # Shuffle the data indices\n",
        "        indices = list(range(len(trainset)))\n",
        "        random.shuffle(indices)\n",
        "\n",
        "        # Partition the data into random sizes for each client\n",
        "        datasets = []\n",
        "        start = 0\n",
        "        for size in sizes:\n",
        "            subset_indices = indices[start: start + size]\n",
        "            subset = torch.utils.data.Subset(trainset, subset_indices)\n",
        "            datasets.append(subset)\n",
        "            start += size\n",
        "    else:\n",
        "        raise ValueError(f\"Invalid strategy: {strategy}\")\n",
        "\n",
        "    # Split each partition into train/val and create DataLoader\n",
        "    trainloaders = []\n",
        "    valloaders = []\n",
        "    for ds in datasets:\n",
        "        len_val = len(ds) // 10  # 10 % validation set\n",
        "        len_train = len(ds) - len_val\n",
        "        lengths = [len_train, len_val]\n",
        "        ds_train, ds_val = random_split(ds, lengths, torch.Generator().manual_seed(42))\n",
        "        trainloaders.append(DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True))\n",
        "        valloaders.append(DataLoader(ds_val, batch_size=BATCH_SIZE))\n",
        "    testloader = DataLoader(testset, batch_size=BATCH_SIZE)\n",
        "    return trainloaders, valloaders, testloader\n",
        "\n",
        "trainloaders, valloaders, testloader = load_datasets()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gy0uk3nbxBr3",
        "outputId": "89ecfde4-f686-46da-f9a1-42b679dbe3ba"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./dataset/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:06<00:00, 28234362.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./dataset/cifar-10-python.tar.gz to ./dataset\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mp4qXPDCFD4Q"
      },
      "source": [
        "We now have a list of ten training sets and ten validation sets (`trainloaders` and `valloaders`) representing the data of ten different organizations. Each `trainloader`/`valloader` pair contains 4500 training examples and 500 validation examples. There's also a single `testloader` (we did not split the test set). Again, this is only necessary for building research or educational systems, actual federated learning systems have their data naturally distributed across multiple partitions.\n",
        "\n",
        "Let's take a look at the first batch of images and labels in the first training set (i.e., `trainloaders[0]`) before we move on:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "YkoGKBF5FD4Q"
      },
      "outputs": [],
      "source": [
        "images, labels = next(iter(trainloaders[0]))\n",
        "\n",
        "# Reshape and convert images to a NumPy array\n",
        "# matplotlib requires images with the shape (height, width, 3)\n",
        "images = images.permute(0, 2, 3, 1).numpy()\n",
        "# Denormalize\n",
        "images = images / 2 + 0.5\n",
        "\n",
        "# Create a figure and a grid of subplots\n",
        "# fig, axs = plt.subplots(4, 8, figsize=(12, 6))\n",
        "\n",
        "# # Loop over the images and plot them\n",
        "# for i, ax in enumerate(axs.flat):\n",
        "#     ax.imshow(images[i])\n",
        "#     ax.set_title(CLASSES[labels[i]])\n",
        "#     ax.axis(\"off\")\n",
        "\n",
        "# # Show the plot\n",
        "# fig.tight_layout()\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hY40E1zFFD4R"
      },
      "source": [
        "### Defining the model\n",
        "\n",
        "We use the simple CNN described in the [PyTorch tutorial](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#define-a-convolutional-neural-network):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Te4C6-IGFD4R"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self) -> None:\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUOfn3YuFD4R"
      },
      "source": [
        "Let's continue with the usual training and test functions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "W6RLXYjAFD4R"
      },
      "outputs": [],
      "source": [
        "def train(net, trainloader, epochs: int, verbose=False):\n",
        "    \"\"\"Train the network on the training set.\"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(net.parameters())\n",
        "    net.train()\n",
        "    for epoch in range(epochs):\n",
        "        correct, total, epoch_loss = 0, 0, 0.0\n",
        "        for images, labels in trainloader:\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            # Metrics\n",
        "            epoch_loss += loss\n",
        "            total += labels.size(0)\n",
        "            correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
        "        epoch_loss /= len(trainloader.dataset)\n",
        "        epoch_acc = correct / total\n",
        "        if verbose:\n",
        "            print(f\"Epoch {epoch+1}: train loss {epoch_loss}, accuracy {epoch_acc}\")\n",
        "\n",
        "\n",
        "def test(net, testloader):\n",
        "    \"\"\"Evaluate the network on the entire test set.\"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    correct, total, loss = 0, 0, 0.0\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        for images, labels in testloader:\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            outputs = net(images)\n",
        "            loss += criterion(outputs, labels).item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    loss /= len(testloader.dataset)\n",
        "    accuracy = correct / total\n",
        "    return loss, accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If 'non-iid' is chosen, it generates non-iid data distribution for the clients. Specifically, for each client, it randomly chooses 5 out of 10 classes, and samples 100 images from each of those classes. This creates a situation where each client has a different distribution of classes, and some classes may be completely missing from some clients. This is just one possible way to create non-iid data, and you can modify it to suit your specific use case.\n",
        "\n",
        "Note that the non-iid strategy can result in some clients having very little data, especially if they happen to get classes with very few samples. This can affect the learning performance, and\n"
      ],
      "metadata": {
        "id": "BBERk7Mo0JFQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If 'random-percentage\" is chosen then randomly generate a distribution of class counts (with each count representing the number of samples of a particular class that the client should have), and then use this distribution to randomly select samples from the training set. The class_counts list contains the number of samples for each class in the entire training set, and the class_distribution list contains a randomly generated distribution of class counts for each client. We then use the % operator to determine which class a particular sample belongs to, and use the corresponding distribution value to \n",
        "decide whether to include it in the client's dataset.\n",
        "\n",
        "This implementation uses the 'random' strategy to randomly divide the training set into NUM_CLIENTS partitions with different percentage distribution of classes. The implementation first counts the number of samples for each class in the training set. Then, for each class, it randomly partitions the samples for that class into NUM_CLIENTS partitions, where each partition has a different percentage distribution of samples from that class. Finally, the implementation creates a Subset object for each partition and returns the list of these objects as datasets. The rest of the implementation is the same as the original load_datasets function."
      ],
      "metadata": {
        "id": "5nVddpzpJlUH"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPZJ7BZlFD4S"
      },
      "source": [
        "### Training the model\n",
        "\n",
        "We now have all the basic building blocks we need: a dataset, a model, a training function, and a test function. Let's put them together to train the model on the dataset of one of our organizations (`trainloaders[0]`). This simulates the reality of most machine learning projects today: each organization has their own data and trains models only on this internal data: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ldqWF4CAFD4S"
      },
      "outputs": [],
      "source": [
        "trainloader = trainloaders[0]\n",
        "valloader = valloaders[0]\n",
        "net = Net().to(DEVICE)\n",
        "\n",
        "# for epoch in range(5):\n",
        "#     train(net, trainloader, 1)\n",
        "#     loss, accuracy = test(net, valloader)\n",
        "#     print(f\"Epoch {epoch+1}: validation loss {loss}, accuracy {accuracy}\")\n",
        "\n",
        "# loss, accuracy = test(net, testloader)\n",
        "# print(f\"Final test set performance:\\n\\tloss {loss}\\n\\taccuracy {accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9slG_efFD4S"
      },
      "source": [
        "Training the simple CNN on our CIFAR-10 split for 5 epochs should result in a test set accuracy of about 41%, which is not good, but at the same time, it doesn't really matter for the purposes of this tutorial. The intent was just to show a simplistic centralized training pipeline that sets the stage for what comes next - federated learning!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Laduo8uOFD4S"
      },
      "source": [
        "### Updating model parameters\n",
        "\n",
        "In federated learning, the server sends the global model parameters to the client, and the client updates the local model with the parameters received from the server. It then trains the model on the local data (which changes the model parameters locally) and sends the updated/changed model parameters back to the server (or, alternatively, it sends just the gradients back to the server, not the full model parameters).\n",
        "\n",
        "We need two helper functions to update the local model with parameters received from the server and to get the updated model parameters from the local model: `set_parameters` and `get_parameters`. The following two functions do just that for the PyTorch model above.\n",
        "\n",
        "The details of how this works are not really important here (feel free to consult the PyTorch documentation if you want to learn more). In essence, we use `state_dict` to access PyTorch model parameter tensors. The parameter tensors are then converted to/from a list of NumPy ndarray's (which Flower knows how to serialize/deserialize):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "oQnk0ZsdFD4S"
      },
      "outputs": [],
      "source": [
        "def get_parameters(net) -> List[np.ndarray]:\n",
        "    parameters = [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
        "    # print(f\"Parameters size: {get_params_size(parameters)} bytes\")\n",
        "    return parameters\n",
        "\n",
        "\n",
        "def set_parameters(net, parameters: List[np.ndarray]):\n",
        "    params_dict = zip(net.state_dict().keys(), parameters)\n",
        "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
        "    net.load_state_dict(state_dict, strict=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hi01ChcRFD4S"
      },
      "source": [
        "### Implementing a Flower client\n",
        "\n",
        "With that out of the way, let's move on to the interesting part. Federated learning systems consist of a server and multiple clients. In Flower, we create clients by implementing subclasses of `flwr.client.Client` or `flwr.client.NumPyClient`. We use `NumPyClient` in this tutorial because it is easier to implement and requires us to write less boilerplate.\n",
        "\n",
        "To implement the Flower client, we create a subclass of `flwr.client.NumPyClient` and implement the three methods `get_parameters`, `fit`, and `evaluate`:\n",
        "\n",
        "* `get_parameters`: Return the current local model parameters\n",
        "* `fit`: Receive model parameters from the server, train the model parameters on the local data, and return the (updated) model parameters to the server\n",
        "* `evaluate`: Receive model parameters from the server, evaluate the model parameters on the local data, and return the evaluation result to the server\n",
        "\n",
        "We mentioned that our clients will use the previously defined PyTorch components for model training and evaluation. Let's see a simple Flower client implementation that brings everything together:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "fRl-goiZCkcV"
      },
      "outputs": [],
      "source": [
        "def get_params_size(parameters):\n",
        "    total_size = 0\n",
        "    for p in parameters:\n",
        "        total_size += sys.getsizeof(p)\n",
        "        if isinstance(p, np.ndarray):\n",
        "            total_size += p.nbytes\n",
        "    return total_size\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "FYENyfxgFD4S"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "# import logging\n",
        "# import multiprocessing\n",
        "\n",
        "class FlowerClient(fl.client.NumPyClient):\n",
        "\n",
        "      def __init__(self, cid, net, trainloader, valloader):\n",
        "          self.cid = cid\n",
        "          self.net = net\n",
        "          self.trainloader = trainloader\n",
        "          self.valloader = valloader\n",
        "          # self.logger = logging.getLogger(f\"Client {cid}\")\n",
        "          # self.logger.setLevel(logging.INFO)\n",
        "          # self.file_handler = logging.FileHandler(f\"client_{cid}_log.txt\")\n",
        "          # self.logger.addHandler(self.file_handler)\n",
        "\n",
        "      def get_parameters(self, config):\n",
        "          return get_parameters(self.net)\n",
        "\n",
        "      def fit(self, parameters, config):\n",
        "        with open(f\"client_{self.cid}_log.txt\", \"a\") as f:\n",
        "          set_parameters(self.net, parameters)\n",
        "          start_time = time.time()\n",
        "          train(self.net, self.trainloader, epochs=2)\n",
        "          end_time = time.time()\n",
        "          total_time = end_time - start_time\n",
        "          adj_total_time = (\"%.3f\" %(total_time))\n",
        "          parameters = get_parameters(self.net)\n",
        "          print(f\"Client ID: {self.cid}, Parameters size: {get_params_size(parameters)} bytes, Total Time: {adj_total_time}\")\n",
        "          f.write(f\"Client ID: {self.cid}, Parameters size: {get_params_size(parameters)} bytes, Total Time: {adj_total_time}\\n\")\n",
        "          f.write(\"\\n\")\n",
        "\n",
        "          with open(\"param_output.txt\", \"w\") as f:\n",
        "\n",
        "            print(\"Sending back new parameters to the global model:\", parameters, file=f)\n",
        "          return parameters, len(self.trainloader), {}\n",
        "\n",
        "      def evaluate(self, parameters, config):\n",
        "        # with open(f\"client_{self.cid}_evaluate.txt\", \"w\") as d:\n",
        "        with open(f\"client_{self.cid}_evaluate.txt\", \"a\") as f:\n",
        "          set_parameters(self.net, parameters)\n",
        "          loss, accuracy = test(self.net, self.valloader)\n",
        "          print(f\"Client ID: {self.cid}, Loss: {loss}, Accuracy: {accuracy}\")\n",
        "          f.write(f\"Client ID: {self.cid}, Loss: {loss}, Accuracy: {accuracy}\")\n",
        "          f.write(\"\\n\")\n",
        "          return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6hsZG2cFD4S"
      },
      "source": [
        "Our class `FlowerClient` defines how local training/evaluation will be performed and allows Flower to call the local training/evaluation through `fit` and `evaluate`. Each instance of `FlowerClient` represents a *single client* in our federated learning system. Federated learning systems have multiple clients (otherwise, there's not much to federate), so each client will be represented by its own instance of `FlowerClient`. If we have, for example, three clients in our workload, then we'd have three instances of `FlowerClient`. Flower calls `FlowerClient.fit` on the respective instance when the server selects a particular client for training (and `FlowerClient.evaluate` for evaluation).\n",
        "\n",
        "### Using the Virtual Client Engine\n",
        "\n",
        "In this notebook, we want to simulate a federated learning system with 10 clients on a single machine. This means that the server and all 10 clients will live on a single machine and share resources such as CPU, GPU, and memory. Having 10 clients would mean having 10 instances of `FlowerClient` in memory. Doing this on a single machine can quickly exhaust the available memory resources, even if only a subset of these clients participates in a single round of federated learning.\n",
        "\n",
        "In addition to the regular capabilities where server and clients run on multiple machines, Flower, therefore, provides special simulation capabilities that create `FlowerClient` instances only when they are actually necessary for training or evaluation. To enable the Flower framework to create clients when necessary, we need to implement a function called `client_fn` that creates a `FlowerClient` instance on demand. Flower calls `client_fn` whenever it needs an instance of one particular client to call `fit` or `evaluate` (those instances are usually discarded after use, so they should not keep any local state). Clients are identified by a client ID, or short `cid`. The `cid` can be used, for example, to load different local data partitions for different clients, as can be seen below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "tpF7mC7NFD4T"
      },
      "outputs": [],
      "source": [
        "def client_fn(cid: str) -> FlowerClient:\n",
        "    \"\"\"Create a Flower client representing a single organization.\"\"\"\n",
        "\n",
        "    # Load model\n",
        "\n",
        "    # # List of acceptable cids\n",
        "    # acceptable_cids = [\"10\", \"2\", \"4\", \"7\", \"8\", \"9\"]  # replace with your cids\n",
        "\n",
        "    # # Check if provided cid is acceptable\n",
        "    # if cid not in acceptable_cids:\n",
        "    #     raise ValueError(f\"Unrecognized cid: {cid}\")\n",
        "\n",
        "\n",
        "    net = Net().to(DEVICE)\n",
        "\n",
        "    # Load data (CIFAR-10)\n",
        "    # Note: each client gets a different trainloader/valloader, so each client\n",
        "    # will train and evaluate on their own unique data\n",
        "    trainloader = trainloaders[int(cid)]\n",
        "    valloader = valloaders[int(cid)]\n",
        "    return FlowerClient(cid, net, trainloader, valloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5skL5fIuFD4T"
      },
      "source": [
        "### Starting the training\n",
        "\n",
        "We now have the class `FlowerClient` which defines client-side training/evaluation and `client_fn` which allows Flower to create `FlowerClient` instances whenever it needs to call `fit` or `evaluate` on one particular client. The last step is to start the actual simulation using `flwr.simulation.start_simulation`. \n",
        "\n",
        "The function `start_simulation` accepts a number of arguments, amongst them the `client_fn` used to create `FlowerClient` instances, the number of clients to simulate (`num_clients`), the number of federated learning rounds (`num_rounds`), and the strategy. The strategy encapsulates the federated learning approach/algorithm, for example, *Federated Averaging* (FedAvg).\n",
        "\n",
        "Flower has a number of built-in strategies, but we can also use our own strategy implementations to customize nearly all aspects of the federated learning approach. For this example, we use the built-in `FedAvg` implementation and customize it using a few basic parameters. The last step is the actual call to `start_simulation` which - you guessed it - starts the simulation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "vhOMGAHcFD4T"
      },
      "outputs": [],
      "source": [
        "def weighted_average(metrics: List[Tuple[int, Metrics]]) -> Metrics:\n",
        "    # Multiply accuracy of each client by number of examples used\n",
        "    accuracies = [num_examples * m[\"accuracy\"] for num_examples, m in metrics]\n",
        "    examples = [num_examples for num_examples, _ in metrics]\n",
        "\n",
        "    # Aggregate and return custom metric (weighted average)\n",
        "    return {\"accuracy\": sum(accuracies) / sum(examples)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "z9vyDhIN-2Wd"
      },
      "outputs": [],
      "source": [
        "#function to remove old files (possibly for colab only*)\n",
        "\n",
        "import os\n",
        "import glob\n",
        "\n",
        "file_key = \"client*.txt\"\n",
        "for del_file in glob.glob(file_key):\n",
        "  os.remove(del_file)\n",
        "\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ems1glDkFD4T"
      },
      "source": [
        "The only thing left to do is to tell the strategy to call this function whenever it receives evaluation metric dictionaries from the clients:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "I1HsthQuFD4T",
        "outputId": "4d01ec63-b0fe-4979-ed28-e6454a1e10bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2023-06-08 14:44:58,999 | app.py:146 | Starting Flower simulation, config: ServerConfig(num_rounds=9, round_timeout=None)\n",
            "INFO:flwr:Starting Flower simulation, config: ServerConfig(num_rounds=9, round_timeout=None)\n",
            "2023-06-08 14:45:02,797\tINFO worker.py:1625 -- Started a local Ray instance.\n",
            "INFO flwr 2023-06-08 14:45:04,918 | app.py:180 | Flower VCE: Ray initialized with resources: {'CPU': 2.0, 'GPU': 1.0, 'memory': 7861850112.0, 'object_store_memory': 3930925056.0, 'node:172.28.0.12': 1.0}\n",
            "INFO:flwr:Flower VCE: Ray initialized with resources: {'CPU': 2.0, 'GPU': 1.0, 'memory': 7861850112.0, 'object_store_memory': 3930925056.0, 'node:172.28.0.12': 1.0}\n",
            "INFO flwr 2023-06-08 14:45:04,923 | server.py:86 | Initializing global parameters\n",
            "INFO:flwr:Initializing global parameters\n",
            "INFO flwr 2023-06-08 14:45:04,931 | server.py:273 | Requesting initial parameters from one random client\n",
            "INFO:flwr:Requesting initial parameters from one random client\n",
            "INFO flwr 2023-06-08 14:45:11,986 | server.py:277 | Received initial parameters from one random client\n",
            "INFO:flwr:Received initial parameters from one random client\n",
            "INFO flwr 2023-06-08 14:45:11,990 | server.py:88 | Evaluating initial parameters\n",
            "INFO:flwr:Evaluating initial parameters\n",
            "INFO flwr 2023-06-08 14:45:11,992 | server.py:101 | FL starting\n",
            "INFO:flwr:FL starting\n",
            "DEBUG flwr 2023-06-08 14:45:11,994 | server.py:218 | fit_round 1: strategy sampled 10 clients (out of 10)\n",
            "DEBUG:flwr:fit_round 1: strategy sampled 10 clients (out of 10)\n",
            "ERROR flwr 2023-06-08 14:45:27,202 | ray_client_proxy.py:87 | \u001b[36mray::launch_and_fit()\u001b[39m (pid=1932, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flwr/simulation/ray_transport/ray_client_proxy.py\", line 147, in launch_and_fit\n",
            "    client: Client = _create_client(client_fn, cid)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flwr/simulation/ray_transport/ray_client_proxy.py\", line 168, in _create_client\n",
            "    client_like: ClientLike = client_fn(cid)\n",
            "  File \"<ipython-input-16-d6f950038e92>\", line 11, in client_fn\n",
            "ValueError: Unrecognized cid: 3\n",
            "ERROR:flwr:\u001b[36mray::launch_and_fit()\u001b[39m (pid=1932, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flwr/simulation/ray_transport/ray_client_proxy.py\", line 147, in launch_and_fit\n",
            "    client: Client = _create_client(client_fn, cid)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flwr/simulation/ray_transport/ray_client_proxy.py\", line 168, in _create_client\n",
            "    client_like: ClientLike = client_fn(cid)\n",
            "  File \"<ipython-input-16-d6f950038e92>\", line 11, in client_fn\n",
            "ValueError: Unrecognized cid: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=1991)\u001b[0m Client ID: 7, Parameters size: 249288 bytes, Total Time: 5.238\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2083)\u001b[0m Client ID: 8, Parameters size: 249288 bytes, Total Time: 4.331\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2164)\u001b[0m Client ID: 2, Parameters size: 249288 bytes, Total Time: 3.480\n",
            "\u001b[2m\u001b[1m\u001b[36m(autoscaler +1m20s)\u001b[0m Tip: use `ray status` to view detailed cluster status. To disable these messages, set RAY_SCHEDULER_EVENTS=0.\n",
            "\u001b[2m\u001b[1m\u001b[33m(autoscaler +1m20s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=2256)\u001b[0m Client ID: 9, Parameters size: 249288 bytes, Total Time: 3.483\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR flwr 2023-06-08 14:46:22,060 | ray_client_proxy.py:87 | \u001b[36mray::launch_and_fit()\u001b[39m (pid=2349, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flwr/simulation/ray_transport/ray_client_proxy.py\", line 147, in launch_and_fit\n",
            "    client: Client = _create_client(client_fn, cid)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flwr/simulation/ray_transport/ray_client_proxy.py\", line 168, in _create_client\n",
            "    client_like: ClientLike = client_fn(cid)\n",
            "  File \"<ipython-input-16-d6f950038e92>\", line 11, in client_fn\n",
            "ValueError: Unrecognized cid: 5\n",
            "ERROR:flwr:\u001b[36mray::launch_and_fit()\u001b[39m (pid=2349, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flwr/simulation/ray_transport/ray_client_proxy.py\", line 147, in launch_and_fit\n",
            "    client: Client = _create_client(client_fn, cid)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flwr/simulation/ray_transport/ray_client_proxy.py\", line 168, in _create_client\n",
            "    client_like: ClientLike = client_fn(cid)\n",
            "  File \"<ipython-input-16-d6f950038e92>\", line 11, in client_fn\n",
            "ValueError: Unrecognized cid: 5\n",
            "ERROR flwr 2023-06-08 14:46:29,028 | ray_client_proxy.py:87 | \u001b[36mray::launch_and_fit()\u001b[39m (pid=2418, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flwr/simulation/ray_transport/ray_client_proxy.py\", line 147, in launch_and_fit\n",
            "    client: Client = _create_client(client_fn, cid)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flwr/simulation/ray_transport/ray_client_proxy.py\", line 168, in _create_client\n",
            "    client_like: ClientLike = client_fn(cid)\n",
            "  File \"<ipython-input-16-d6f950038e92>\", line 11, in client_fn\n",
            "ValueError: Unrecognized cid: 0\n",
            "ERROR:flwr:\u001b[36mray::launch_and_fit()\u001b[39m (pid=2418, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flwr/simulation/ray_transport/ray_client_proxy.py\", line 147, in launch_and_fit\n",
            "    client: Client = _create_client(client_fn, cid)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flwr/simulation/ray_transport/ray_client_proxy.py\", line 168, in _create_client\n",
            "    client_like: ClientLike = client_fn(cid)\n",
            "  File \"<ipython-input-16-d6f950038e92>\", line 11, in client_fn\n",
            "ValueError: Unrecognized cid: 0\n",
            "ERROR flwr 2023-06-08 14:46:34,628 | ray_client_proxy.py:87 | \u001b[36mray::launch_and_fit()\u001b[39m (pid=2483, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flwr/simulation/ray_transport/ray_client_proxy.py\", line 147, in launch_and_fit\n",
            "    client: Client = _create_client(client_fn, cid)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flwr/simulation/ray_transport/ray_client_proxy.py\", line 168, in _create_client\n",
            "    client_like: ClientLike = client_fn(cid)\n",
            "  File \"<ipython-input-16-d6f950038e92>\", line 11, in client_fn\n",
            "ValueError: Unrecognized cid: 1\n",
            "ERROR:flwr:\u001b[36mray::launch_and_fit()\u001b[39m (pid=2483, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flwr/simulation/ray_transport/ray_client_proxy.py\", line 147, in launch_and_fit\n",
            "    client: Client = _create_client(client_fn, cid)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flwr/simulation/ray_transport/ray_client_proxy.py\", line 168, in _create_client\n",
            "    client_like: ClientLike = client_fn(cid)\n",
            "  File \"<ipython-input-16-d6f950038e92>\", line 11, in client_fn\n",
            "ValueError: Unrecognized cid: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_fit pid=2540)\u001b[0m Client ID: 4, Parameters size: 249288 bytes, Total Time: 3.547\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR flwr 2023-06-08 14:46:52,702 | ray_client_proxy.py:87 | \u001b[36mray::launch_and_fit()\u001b[39m (pid=2630, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flwr/simulation/ray_transport/ray_client_proxy.py\", line 147, in launch_and_fit\n",
            "    client: Client = _create_client(client_fn, cid)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flwr/simulation/ray_transport/ray_client_proxy.py\", line 168, in _create_client\n",
            "    client_like: ClientLike = client_fn(cid)\n",
            "  File \"<ipython-input-16-d6f950038e92>\", line 11, in client_fn\n",
            "ValueError: Unrecognized cid: 6\n",
            "ERROR:flwr:\u001b[36mray::launch_and_fit()\u001b[39m (pid=2630, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flwr/simulation/ray_transport/ray_client_proxy.py\", line 147, in launch_and_fit\n",
            "    client: Client = _create_client(client_fn, cid)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flwr/simulation/ray_transport/ray_client_proxy.py\", line 168, in _create_client\n",
            "    client_like: ClientLike = client_fn(cid)\n",
            "  File \"<ipython-input-16-d6f950038e92>\", line 11, in client_fn\n",
            "ValueError: Unrecognized cid: 6\n",
            "DEBUG flwr 2023-06-08 14:46:52,713 | server.py:232 | fit_round 1 received 5 results and 5 failures\n",
            "DEBUG:flwr:fit_round 1 received 5 results and 5 failures\n",
            "WARNING flwr 2023-06-08 14:46:52,740 | fedavg.py:243 | No fit_metrics_aggregation_fn provided\n",
            "WARNING:flwr:No fit_metrics_aggregation_fn provided\n",
            "DEBUG flwr 2023-06-08 14:46:52,744 | server.py:168 | evaluate_round 1: strategy sampled 5 clients (out of 10)\n",
            "DEBUG:flwr:evaluate_round 1: strategy sampled 5 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2735)\u001b[0m Client ID: 2, Loss: 0.06183482313156128, Accuracy: 0.324\n",
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=2875)\u001b[0m Client ID: 4, Loss: 0.06150499320030212, Accuracy: 0.33\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR flwr 2023-06-08 14:47:29,897 | ray_client_proxy.py:104 | \u001b[36mray::launch_and_evaluate()\u001b[39m (pid=2939, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flwr/simulation/ray_transport/ray_client_proxy.py\", line 159, in launch_and_evaluate\n",
            "    client: Client = _create_client(client_fn, cid)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flwr/simulation/ray_transport/ray_client_proxy.py\", line 168, in _create_client\n",
            "    client_like: ClientLike = client_fn(cid)\n",
            "  File \"<ipython-input-16-d6f950038e92>\", line 11, in client_fn\n",
            "ValueError: Unrecognized cid: 3\n",
            "ERROR:flwr:\u001b[36mray::launch_and_evaluate()\u001b[39m (pid=2939, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flwr/simulation/ray_transport/ray_client_proxy.py\", line 159, in launch_and_evaluate\n",
            "    client: Client = _create_client(client_fn, cid)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flwr/simulation/ray_transport/ray_client_proxy.py\", line 168, in _create_client\n",
            "    client_like: ClientLike = client_fn(cid)\n",
            "  File \"<ipython-input-16-d6f950038e92>\", line 11, in client_fn\n",
            "ValueError: Unrecognized cid: 3\n",
            "DEBUG flwr 2023-06-08 14:47:36,049 | server.py:182 | evaluate_round 1 received 4 results and 1 failures\n",
            "DEBUG:flwr:evaluate_round 1 received 4 results and 1 failures\n",
            "DEBUG flwr 2023-06-08 14:47:36,054 | server.py:218 | fit_round 2: strategy sampled 10 clients (out of 10)\n",
            "DEBUG:flwr:fit_round 2: strategy sampled 10 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(launch_and_evaluate pid=3010)\u001b[0m Client ID: 7, Loss: 0.061265372514724734, Accuracy: 0.34\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR flwr 2023-06-08 14:47:51,894 | ray_client_proxy.py:87 | \u001b[36mray::launch_and_fit()\u001b[39m (pid=3124, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flwr/simulation/ray_transport/ray_client_proxy.py\", line 147, in launch_and_fit\n",
            "    client: Client = _create_client(client_fn, cid)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flwr/simulation/ray_transport/ray_client_proxy.py\", line 168, in _create_client\n",
            "    client_like: ClientLike = client_fn(cid)\n",
            "  File \"<ipython-input-16-d6f950038e92>\", line 11, in client_fn\n",
            "ValueError: Unrecognized cid: 1\n",
            "ERROR:flwr:\u001b[36mray::launch_and_fit()\u001b[39m (pid=3124, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flwr/simulation/ray_transport/ray_client_proxy.py\", line 147, in launch_and_fit\n",
            "    client: Client = _create_client(client_fn, cid)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flwr/simulation/ray_transport/ray_client_proxy.py\", line 168, in _create_client\n",
            "    client_like: ClientLike = client_fn(cid)\n",
            "  File \"<ipython-input-16-d6f950038e92>\", line 11, in client_fn\n",
            "ValueError: Unrecognized cid: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[1m\u001b[33m(autoscaler +3m11s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3186)\u001b[0m Client ID: 8, Parameters size: 249288 bytes, Total Time: 3.498\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3280)\u001b[0m Client ID: 9, Parameters size: 249288 bytes, Total Time: 4.597\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3366)\u001b[0m Client ID: 7, Parameters size: 249288 bytes, Total Time: 4.308\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3456)\u001b[0m Client ID: 4, Parameters size: 249288 bytes, Total Time: 3.494\n",
            "\u001b[2m\u001b[36m(launch_and_fit pid=3544)\u001b[0m Client ID: 2, Parameters size: 249288 bytes, Total Time: 3.567\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR flwr 2023-06-08 14:48:57,481 | ray_client_proxy.py:87 | \u001b[36mray::launch_and_fit()\u001b[39m (pid=3633, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flwr/simulation/ray_transport/ray_client_proxy.py\", line 147, in launch_and_fit\n",
            "    client: Client = _create_client(client_fn, cid)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flwr/simulation/ray_transport/ray_client_proxy.py\", line 168, in _create_client\n",
            "    client_like: ClientLike = client_fn(cid)\n",
            "  File \"<ipython-input-16-d6f950038e92>\", line 11, in client_fn\n",
            "ValueError: Unrecognized cid: 0\n",
            "ERROR:flwr:\u001b[36mray::launch_and_fit()\u001b[39m (pid=3633, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flwr/simulation/ray_transport/ray_client_proxy.py\", line 147, in launch_and_fit\n",
            "    client: Client = _create_client(client_fn, cid)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flwr/simulation/ray_transport/ray_client_proxy.py\", line 168, in _create_client\n",
            "    client_like: ClientLike = client_fn(cid)\n",
            "  File \"<ipython-input-16-d6f950038e92>\", line 11, in client_fn\n",
            "ValueError: Unrecognized cid: 0\n",
            "ERROR flwr 2023-06-08 14:49:05,778 | ray_client_proxy.py:87 | \u001b[36mray::launch_and_fit()\u001b[39m (pid=3694, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flwr/simulation/ray_transport/ray_client_proxy.py\", line 147, in launch_and_fit\n",
            "    client: Client = _create_client(client_fn, cid)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flwr/simulation/ray_transport/ray_client_proxy.py\", line 168, in _create_client\n",
            "    client_like: ClientLike = client_fn(cid)\n",
            "  File \"<ipython-input-16-d6f950038e92>\", line 11, in client_fn\n",
            "ValueError: Unrecognized cid: 5\n",
            "ERROR:flwr:\u001b[36mray::launch_and_fit()\u001b[39m (pid=3694, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flwr/simulation/ray_transport/ray_client_proxy.py\", line 147, in launch_and_fit\n",
            "    client: Client = _create_client(client_fn, cid)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flwr/simulation/ray_transport/ray_client_proxy.py\", line 168, in _create_client\n",
            "    client_like: ClientLike = client_fn(cid)\n",
            "  File \"<ipython-input-16-d6f950038e92>\", line 11, in client_fn\n",
            "ValueError: Unrecognized cid: 5\n",
            "ERROR flwr 2023-06-08 14:49:11,601 | ray_client_proxy.py:87 | \u001b[36mray::launch_and_fit()\u001b[39m (pid=3766, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flwr/simulation/ray_transport/ray_client_proxy.py\", line 147, in launch_and_fit\n",
            "    client: Client = _create_client(client_fn, cid)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flwr/simulation/ray_transport/ray_client_proxy.py\", line 168, in _create_client\n",
            "    client_like: ClientLike = client_fn(cid)\n",
            "  File \"<ipython-input-16-d6f950038e92>\", line 11, in client_fn\n",
            "ValueError: Unrecognized cid: 3\n",
            "ERROR:flwr:\u001b[36mray::launch_and_fit()\u001b[39m (pid=3766, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flwr/simulation/ray_transport/ray_client_proxy.py\", line 147, in launch_and_fit\n",
            "    client: Client = _create_client(client_fn, cid)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/flwr/simulation/ray_transport/ray_client_proxy.py\", line 168, in _create_client\n",
            "    client_like: ClientLike = client_fn(cid)\n",
            "  File \"<ipython-input-16-d6f950038e92>\", line 11, in client_fn\n",
            "ValueError: Unrecognized cid: 3\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/flwr/server/server.py\u001b[0m in \u001b[0;36mfit_clients\u001b[0;34m(client_instructions, max_workers, timeout)\u001b[0m\n\u001b[1;32m    333\u001b[0m         }\n\u001b[0;32m--> 334\u001b[0;31m         finished_fs, _ = concurrent.futures.wait(\n\u001b[0m\u001b[1;32m    335\u001b[0m             \u001b[0mfs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubmitted_fs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(fs, timeout, return_when)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m     \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    606\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-4e2cf8e66600>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mclient_resources\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"num_gpus\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Start simulation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m fl.simulation.start_simulation(\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mclient_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclient_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mnum_clients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_CLIENTS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/flwr/simulation/app.py\u001b[0m in \u001b[0;36mstart_simulation\u001b[0;34m(client_fn, num_clients, clients_ids, client_resources, server, config, strategy, client_manager, ray_init_args, keep_initialised)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;31m# Start training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     hist = _fl(\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0mserver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitialized_server\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitialized_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/flwr/server/app.py\u001b[0m in \u001b[0;36m_fl\u001b[0;34m(server, config)\u001b[0m\n\u001b[1;32m    215\u001b[0m ) -> History:\n\u001b[1;32m    216\u001b[0m     \u001b[0;31m# Fit model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m     \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mserver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_rounds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m     \u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mINFO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"app_fit: losses_distributed %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses_distributed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mINFO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"app_fit: metrics_distributed_fit %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics_distributed_fit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/flwr/server/server.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, num_rounds, timeout)\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcurrent_round\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_rounds\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0;31m# Train model and replace previous global model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             \u001b[0mres_fit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_round\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mserver_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurrent_round\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mres_fit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m                 \u001b[0mparameters_prime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_metrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres_fit\u001b[0m  \u001b[0;31m# fit_metrics_aggregated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/flwr/server/server.py\u001b[0m in \u001b[0;36mfit_round\u001b[0;34m(self, server_round, timeout)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;31m# Collect `fit` results from all clients participating in this round\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m         results, failures = fit_clients(\n\u001b[0m\u001b[1;32m    228\u001b[0m             \u001b[0mclient_instructions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclient_instructions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0mmax_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_workers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/flwr/server/server.py\u001b[0m in \u001b[0;36mfit_clients\u001b[0;34m(client_instructions, max_workers, timeout)\u001b[0m\n\u001b[1;32m    327\u001b[0m ) -> FitResultsAndFailures:\n\u001b[1;32m    328\u001b[0m     \u001b[0;34m\"\"\"Refine parameters concurrently on all selected clients.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mconcurrent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfutures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mThreadPoolExecutor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_workers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m         submitted_fs = {\n\u001b[1;32m    331\u001b[0m             \u001b[0mexecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfit_client\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient_proxy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_tb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 649\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    650\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/concurrent/futures/thread.py\u001b[0m in \u001b[0;36mshutdown\u001b[0;34m(self, wait, cancel_futures)\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_threads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m                 \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m     \u001b[0mshutdown\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_base\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1096\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1097\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1116\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1117\u001b[0m                 \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Create FedAvg strategy\n",
        "strategy = fl.server.strategy.FedAvg(\n",
        "    fraction_fit=0.8,\n",
        "    fraction_evaluate=0.5,\n",
        "    min_fit_clients=10,\n",
        "    min_evaluate_clients=5,\n",
        "    min_available_clients=10,\n",
        "    evaluate_metrics_aggregation_fn=weighted_average,  # <-- pass the metric aggregation function\n",
        ")\n",
        "client_resources = None\n",
        "if DEVICE.type == \"cuda\":\n",
        "    client_resources = {\"num_gpus\": 1}\n",
        "# Start simulation\n",
        "fl.simulation.start_simulation(\n",
        "    client_fn=client_fn,\n",
        "    num_clients=NUM_CLIENTS,\n",
        "    config=fl.server.ServerConfig(num_rounds=9),\n",
        "    strategy=strategy,\n",
        "    client_resources=client_resources,\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61nWXlfGiWjG"
      },
      "outputs": [],
      "source": [
        "\n",
        "file_key = \"client*.txt\"\n",
        "file_name = \"collect_logs\"\n",
        "input_file_name = file_name + '.txt'\n",
        "with open(input_file_name, \"w\") as outfile:\n",
        "  for file in glob.glob(file_key):\n",
        "    with open(file, 'r') as infile:\n",
        "      outfile.write(infile.read())\n",
        "      outfile.write(\"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f3QbIAdh3WGB"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "flower-3.7.12",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}